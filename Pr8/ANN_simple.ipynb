{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0163a505-5e40-4639-9dba-44713317c211",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m hidden_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mБрой неврони от скрития слой\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m learn_repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mБрой повторения на обучаването\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\numpy\\__init__.py:127\u001b[0m\n\u001b[0;32m    124\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning from numpy source directory.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# Allow distributors to run custom init code before importing numpy.core\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__config__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show \u001b[38;5;28;01mas\u001b[39;00m show_config\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\numpy\\_distributor_init.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" Distributor init file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mDistributors: you can add custom code here to support particular distributions\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mcan safely replace this file with your own version.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmkl\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     __mkl_version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{MajorVersion}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{MinorVersion}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{UpdateVersion}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmkl\u001b[38;5;241m.\u001b[39mget_version())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\mkl\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_rtld \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m RTLD_for_MKL():\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mklinit\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m RTLD_for_MKL\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m sys\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hidden_layers = int(input(\"Брой неврони от скрития слой\"))\n",
    "learn_repeat = int(input(\"Брой повторения на обучаването\"))\n",
    "data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_and = np.array([0,0,0,1])\n",
    "y_or = np.array([0,1,1,1])\n",
    "y_xor = np.array([0,1,1,0])\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "weights_hidden = np.random.uniform(-0.05, 0.05, (hidden_layers, data.shape[1]))\n",
    "weights_output = np.random.uniform(-0.05, 0.05, (1, hidden_layers))\n",
    "\n",
    "for i in range(learn_repeat):\n",
    "    hidden = np.dot(weights_hidden, data.T)\n",
    "    # print(hidden.shape)\n",
    "    hidden = sigmoid(hidden)\n",
    "    output = np.dot(weights_output, hidden)\n",
    "    # print(output.shape)\n",
    "    print(output)\n",
    "    weights_output = weights_output + 0.1 * output*(1-output)*(y_xor - output)\n",
    "    weights_hidden = weights_hidden + 0.1 * np.dot((hidden*(1-hidden)).T, (weights_output.T * (y_xor - output))).T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ecf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Инициализация на теглата\n",
    "        self.weights_input_hidden = np.random.uniform(-0.05, 0.05, (input_size, hidden_size))\n",
    "        self.weights_hidden_output = np.random.uniform(-0.05, 0.05, (hidden_size, output_size))\n",
    "        \n",
    "        self.bias_hidden = np.zeros(hidden_size)\n",
    "        self.bias_output = np.zeros(output_size)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Изчисляване на активациите\n",
    "        self.hidden_input = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
    "        \n",
    "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.final_output = self.sigmoid(self.final_input)\n",
    "\n",
    "        return self.final_output\n",
    "\n",
    "    def backward(self, inputs, targets):\n",
    "        # Изчисляване на грешките\n",
    "        output_errors = targets - self.final_output\n",
    "        output_delta = output_errors * self.sigmoid_derivative(self.final_output)\n",
    "\n",
    "        hidden_errors = np.dot(output_delta, self.weights_hidden_output.T)\n",
    "        hidden_delta = hidden_errors * self.sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        # Обновяване на теглата\n",
    "        self.weights_hidden_output += self.learning_rate * np.dot(self.hidden_output.T, output_delta)\n",
    "        self.bias_output += self.learning_rate * output_delta.sum(axis=0)\n",
    "\n",
    "        self.weights_input_hidden += self.learning_rate * np.dot(inputs.T, hidden_delta)\n",
    "        self.bias_hidden += self.learning_rate * hidden_delta.sum(axis=0)\n",
    "\n",
    "    def train(self, inputs, targets, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            outputs = self.forward(inputs)\n",
    "            self.backward(inputs, targets)\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                loss = np.mean((targets - outputs) ** 2)\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Брой входни, скрити и изходни неврони\n",
    "input_size = 2  # Примерен брой атрибути\n",
    "hidden_size = 5 # Параметър\n",
    "output_size = 1 # Примерен брой класове\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Примерни данни\n",
    "inputs = np.array([[0, 0], [ 0, 1], [1, 0], [1, 1]])\n",
    "targets = np.array([ [0], [1], [1], [0]])\n",
    "\n",
    "# Създаване и обучение на мрежата\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)\n",
    "nn.train(inputs, targets, epochs=1000)\n",
    "\n",
    "# Показване на резултатите след трениране\n",
    "print(\"\\nResults after training:\")\n",
    "for i, input_sample in enumerate(inputs):\n",
    "    prediction = nn.forward(input_sample)\n",
    "    print(f\"Input: {input_sample}, Predicted: {prediction}, Target: {targets[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a533a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyS(X, Y, w, b):\n",
    "\t# X.shape = (S,N) Y.shape = (S), W.shape = (N) \n",
    "    v = sigmoid(np.dot(X,w)+b)\n",
    "    p = (1-Y) + (2*Y-1)*v\n",
    "    ce = -np.mean(np.log(p))\n",
    "    return ce\n",
    "\n",
    "def gradCrossEntropyS(X,Y,w,b):\n",
    "    g = Y - sigmoid(np.dot(X,w)+b)\n",
    "    db = -np.mean(g)\n",
    "    dw = -np.mean( g[:,np.newaxis] * X,axis=0)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d422b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74791612 0.74870214 0.74875909 0.74954269]\n",
      "0.5612593570070752\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# hidden_layers = int(input(\"Брой неврони от скрития слой\"))\n",
    "# learn_repeat = int(input(\"Брой повторения на обучаването\"))\n",
    "k = 5\n",
    "learn_repeat = 100\n",
    "learning_rate = 0.5\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_and = np.array([0,0,0,1])\n",
    "y_or = np.array([0,1,1,1])\n",
    "y_xor = np.array([0,1,1,0])\n",
    "\n",
    "y = y_or\n",
    "\n",
    "Wh = np.random.uniform(-0.1, 0.1, (X.shape[1], k))\n",
    "bh = np.random.uniform(-0.1, 0.1, (k,))\n",
    "\n",
    "Wo = np.random.uniform(-0.1, 0.1, (k, ))\n",
    "bo = np.random.uniform(-0.1, 0.1)\n",
    "\n",
    "for i in range(learn_repeat):\n",
    "    q = np.dot(X, Wh) + bh\n",
    "    r = sigmoid(q)\n",
    "    s = np.dot(r, Wo) + bo\n",
    "    sc = sigmoid(s)\n",
    "    p = (1-y) + (2*y-1)*sc\n",
    "    error = -np.mean(np.log(p))\n",
    "    # print(p)\n",
    "    # print(error)\n",
    "    \n",
    "    dWo, dbo = gradCrossEntropyS(r,y,Wo,bo)\n",
    "    ds = -np.mean(y - sc)\n",
    "    dt = ds\n",
    "    dr = np.outer(np.ones(k), ds).T * np.outer(np.ones(X.shape[0]), Wo)\n",
    "    dq = dr * sigmoid_derivative(q)\n",
    "    dbh = dq\n",
    "    dWh = X.T @ dq\n",
    "    \n",
    "    Wh = Wh - learning_rate * dWh\n",
    "    Wo = Wo - learning_rate * dWo\n",
    "    bh = bh - learning_rate * dbh\n",
    "    bo = bo - learning_rate * dbo\n",
    "print(sc)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6da267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[1090 2090 3090]\n",
      " [2170 4170 6170]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define tensors with hardcoded values\n",
    "A = np.array([\n",
    "    [\n",
    "        [[1000, 0, 0], [2000, 0, 0]],\n",
    "        [[0, 1000, 0], [0, 2000, 0]],\n",
    "        [[0, 0, 1000], [0, 0, 2000]]\n",
    "    ],\n",
    "    [\n",
    "        [[100, 0, 0], [200, 0, 0]],\n",
    "        [[0, 100, 0], [0, 200, 0]],\n",
    "        [[0, 0, 100], [0, 0, 200]]\n",
    "    ],\n",
    "    [\n",
    "        [[10, 0, 0], [30, 0, 0]],\n",
    "        [[0, 10, 0], [0, 30, 0]],\n",
    "        [[0, 0, 10], [0, 0, 30]]\n",
    "    ]\n",
    "])  # Shape (3, 3, 2, 3)\n",
    "\n",
    "B = np.array([\n",
    "    [1, 2, 3],\n",
    "    [1, 1, 1],\n",
    "    [-1, -1, -1]\n",
    "])  # Shape (3, 3)\n",
    "\n",
    "# Reshape B to be broadcastable with A\n",
    "B_broadcasted = B[:, :, np.newaxis, np.newaxis]  # Shape (3, 3, 1)\n",
    "\n",
    "# Perform elementwise multiplication and sum along axis 0\n",
    "result = (A * B_broadcasted).sum(axis=(0,1))\n",
    "\n",
    "print(result.shape)  # Should output (2, 3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272b106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
